\subsection{实验环境配置}
\begin{itemize}
    \item \textbf{安装Python}: 确保Python 3.8+已安装，并配置好环境变量。
    \item \textbf{创建虚拟环境}: 推荐使用conda或venv创建独立的Python虚拟环境，以避免库冲突。
    \begin{verbatim}
        conda create -n obj_det python=3.9
        conda activate obj_det
    \end{verbatim}
    \item \textbf{安装PyTorch/TensorFlow}: 根据硬件（特别是GPU）和操作系统，安装对应版本的深度学习框架。
    \begin{verbatim}
        # PyTorch (CUDA 11.8为例)
        pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
    \end{verbatim}
    \item \textbf{安装其他依赖库}:
    \begin{verbatim}
        pip install numpy opencv-python matplotlib pillow
    \end{verbatim}
    \item \textbf{安装mmcv-full}: 如果选择OpenMMLab系列算法，需要安装mmcv-full。
    \begin{verbatim}
        pip install -U openmim
        mim install mmcv-full
    \end{verbatim}
    \item \textbf{安装ultralytics}: 如果选择YOLOv8等Ultralytics系列算法，需要安装ultralytics。
    \begin{verbatim}
        pip install ultralytics
    \end{verbatim}
\end{itemize}

\subsection{开源项目部署}
\begin{itemize}
    \item \textbf{克隆项目}: 从GitHub等平台克隆所选目标检测算法的开源项目。
    \begin{verbatim}
        git clone https://github.com/ultralytics/ultralytics.git # 例如YOLOv8
        git clone https://github.com/open-mmlab/mmdetection.git # 例如Faster R-CNN, FCOS
    \end{verbatim}
    \item \textbf{安装项目依赖}: 进入项目目录，安装其特有的依赖。
    \begin{verbatim}
        # 例如mmdetection
        cd mmdetection
        pip install -v -e .
    \end{verbatim}
    \item \textbf{下载预训练模型}: 下载对应算法的预训练模型权重文件（通常是.pth或.pt文件）。
\end{itemize}

\subsection{图像数据准备}
\begin{itemize}
    \item \textbf{拍摄图像}: 使用手机或相机在校园内拍摄多张图像，确保图像清晰，包含多种目标。
    \item \textbf{整理数据}: 将拍摄的图像统一存放于一个文件夹中，例如`data/campus_images/`。
\end{itemize}

\subsection{目标检测API调用}
\begin{itemize}
    \item \textbf{编写检测脚本}: 编写Python脚本或Jupyter Notebook，导入已部署的算法库，加载预训练模型，并调用其API进行推理。
    \item \textbf{示例代码结构}:
    \begin{verbatim}
        import cv2
        from ultralytics import YOLO # 或 from mmdet.apis import init_detector, inference_detector

        # 加载模型
        model = YOLO('yolov8n.pt') # 或 model = init_detector(config_file, checkpoint_file, device='cuda:0')

        # 读取图像
        img_path = 'data/campus_images/image_01.jpg'
        img = cv2.imread(img_path)

        # 进行推理
        results = model(img) # 或 result = inference_detector(model, img)

        # 解析结果并可视化
        # ... (此处省略具体解析和可视化代码)
    \end{verbatim}
\end{itemize}

\subsection{结果可视化与分析}
\begin{itemize}
    \item \textbf{可视化}: 在原始图像上绘制检测到的边界框、类别标签和置信度。
    \todo{目标检测结果可视化示例图}
    \item \textbf{定性分析}: 观察不同算法在不同场景下（如光照变化、目标遮挡、小目标、密集目标等）的检测效果。
    \item \textbf{定量分析}: 记录并对比不同算法的推理速度（FPS）和检测精度（如mAP，如果条件允许）。
\end{itemize}
